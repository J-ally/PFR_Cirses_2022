{"cells":[{"cell_type":"code","metadata":{"cell_id":"72bb0adbe2e3437b858f21a1a6712f0d","source_hash":"16bd59e5","execution_start":1674764179425,"execution_millis":2833,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"from sklearn.model_selection import GridSearchCV\nimport torch\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.nn import CrossEntropyLoss\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import transforms\nimport torchvision.models as models\nimport torch.nn as nn\nimport time\nfrom sklearn.metrics import balanced_accuracy_score\n\nimport numpy as np\nimport pandas as pd","block_group":"72bb0adbe2e3437b858f21a1a6712f0d","execution_count":2,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"6241a10a2f574a2b8bed53924ac3dc2b","source_hash":"a8261b99","execution_start":1674764182262,"execution_millis":47,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"train = torchvision.datasets.ImageFolder(root=r\"/work/-20230124-132407/data\", transform=transforms.ToTensor())\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True, num_workers=4)\n\ntest = torchvision.datasets.ImageFolder(root=r\"/work/-20230124-132407/data\", transform=transforms.ToTensor())\ntest_loader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=True, num_workers=4)","block_group":"6241a10a2f574a2b8bed53924ac3dc2b","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"8c4fd21f27dd4677a630382f5e66a300","deepnote_cell_type":"markdown"},"source":"## Equilibrage des données d'entrainement\npermet juste de rééquilibrer les classes en supprimant un sous échantillon aléatoire de données dans la classe majoritaire. De manière à ce que les 2 classes aient à peu près les mêmes effectifs","block_group":"8c4fd21f27dd4677a630382f5e66a300"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"b85efbb1d6864003938986826b7dde21","source_hash":"8eaa400b","execution_start":1674646570222,"execution_millis":9243,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# récupérer les images du train_dataset\nimages = []\nlabels = []\nfor image, label in train:\n    images.append(image)\n    labels.append(label)\nprint(type(images))","block_group":"b85efbb1d6864003938986826b7dde21","execution_count":null,"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d1c5017825a74a729ab37028569159ed","source_hash":"2e5e2648","execution_start":1674646579466,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"print(len(labels))","block_group":"d1c5017825a74a729ab37028569159ed","execution_count":null,"outputs":[{"name":"stdout","text":"2880\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"919e580ac3db40deb191d8298fa0e8d5","source_hash":"bcce962f","execution_start":1674646579474,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# on  vérifie le déséquilibre des classes\nprint(sum(np.array(labels)==1)/len(labels))\nprint(sum(np.array(labels)!=1)/len(labels))","block_group":"919e580ac3db40deb191d8298fa0e8d5","execution_count":null,"outputs":[{"name":"stdout","text":"0.121875\n0.878125\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"cbacf21a98c34a4aa5e0c582134b20ba","source_hash":"70d8dbe6","execution_start":1674646579484,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# indice de tous les 1\nid_train_1 = np.where((np.array(labels)==1))\n\n# on copie notre dataset original pour ensuite supprimer toutes les data classées en 1\ny_train_0 = labels.copy()\nX_train_0 = images.copy()\n\n# on supprimer tous les 1 donc toutes les data classées en 0\nfor i in sorted(id_train_1[0], reverse = True):\n    del y_train_0[i]\n    del X_train_0[i]\n\n# indice de tous les 0\nid_train_0 = np.where((np.array(labels)==0))\n\n# on copie notre dataset original pour ensuite supprimer toutes les data classées en 0\ny_train_1 = labels.copy()\nX_train_1 = images.copy()\n\n# on supprimer tous les 0 donc toutes les data classées en 1\nfor i in sorted(id_train_0[0], reverse = True):\n    del y_train_1[i]\n    del X_train_1[i]","block_group":"cbacf21a98c34a4aa5e0c582134b20ba","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"85e0a7cab7f0436e915645ed65a97643","source_hash":"f62fab0a","execution_start":1674646579489,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"print(len(y_train_1))\nprint(len(X_train_1))","block_group":"85e0a7cab7f0436e915645ed65a97643","execution_count":null,"outputs":[{"name":"stdout","text":"351\n351\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"6a5580f1f08a49b69296f7685a262ee6","source_hash":"d497d71b","execution_start":1674646579542,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# on supprime un sous échantillon aléatoire de la classe majoritaire qui compte 90% des éléments de cette classe\nimport random as rd\n\nX_new_train_0 = X_train_0.copy()\ny_new_train_0 = y_train_0.copy()\n\nlist_index = [k for k in range(len(X_train_0))]\n\nfor i in sorted(rd.sample(list_index,int(len(X_train_0)*0.85)), reverse=True):\n    del X_new_train_0[i]\n    del y_new_train_0[i]\n","block_group":"6a5580f1f08a49b69296f7685a262ee6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"fc183e2fe4e349e297ced406f41e4295","source_hash":"33b3f916","execution_start":1674646579543,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"print(len(X_new_train_0))\nprint(len(y_new_train_0))","block_group":"fc183e2fe4e349e297ced406f41e4295","execution_count":null,"outputs":[{"name":"stdout","text":"380\n380\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"abf2201a904a44ceb2124c390f3dbab3","source_hash":"f25d0529","execution_start":1674646579543,"execution_millis":2995668,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"X_new_train = X_new_train_0 + X_train_1\ny_new_train = y_new_train_0 + y_train_1","block_group":"abf2201a904a44ceb2124c390f3dbab3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"4177bf96951541d19bfdec62aa67f418","source_hash":"c7b7a4d3","execution_start":1674646579586,"execution_millis":2993610,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"# on  vérifie le réquilibrage des classes\nprint(sum(np.array(y_new_train)==1)/len(y_new_train))\nprint(sum(np.array(y_new_train)!=1)/len(y_new_train))","block_group":"4177bf96951541d19bfdec62aa67f418","execution_count":null,"outputs":[{"name":"stdout","text":"0.4801641586867305\n0.5198358413132695\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a28fde1810f346e8a4954f89ed5ecd4a","source_hash":"f8fd3972","execution_start":1674646579587,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"new_inputs = torch.stack([t[0] for t in X_new_train])\nnew_labels = torch.tensor(y_new_train)\nprint(\"Il reste\",len(new_labels),\"données !\")","block_group":"a28fde1810f346e8a4954f89ed5ecd4a","execution_count":null,"outputs":[{"name":"stdout","text":"Il reste 731 données !\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"d69aa5c5112b4939b27b9dd52727621a","source_hash":"e5f53482","execution_start":1674646579587,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"new_train = torch.utils.data.TensorDataset(new_inputs, new_labels)","block_group":"d69aa5c5112b4939b27b9dd52727621a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"1868b5b524434527862497a267ad28ec","deepnote_cell_type":"markdown"},"source":"# Boucle d'entrainement et d'évaluation des performances du modèle","block_group":"1868b5b524434527862497a267ad28ec"},{"cell_type":"markdown","metadata":{"cell_id":"d4eca7e1726143cd962898250453d8bf","deepnote_cell_type":"markdown"},"source":"Pour le moment, nous avons enlever juste le dernier neurone.\nEn fonction des résultats obtenus nous devrons probablement enlever quelques couches vers la fin.","block_group":"d4eca7e1726143cd962898250453d8bf"},{"cell_type":"markdown","metadata":{"cell_id":"e0027325a3d2487ba0e0f83a898dc6cd","deepnote_cell_type":"markdown"},"source":"## Fonction d'entrainement du modèle","block_group":"e0027325a3d2487ba0e0f83a898dc6cd"},{"cell_type":"code","metadata":{"cell_id":"01fd5475afa84136b84fbc7e85f96cbe","source_hash":"ff860ba7","execution_start":1674764249514,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def train(model, train_loader, optimizer, criterion):\n    \"\"\"\n    Cette fonction permet d'entrainer un réseau de neuronne :\n        -model : le réseau à entrainer\n        -train_loader : le set d'entrainement (issus de torch.utils.data.DataLoader)\n        -optimizer : choix de l'optimiseur\n        -criterion : choix de la fonction de coût\n    \"\"\"\n    model.train()\n    for inputs, labels in train_loader:\n        #réinitialisation du gradient\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()","block_group":"01fd5475afa84136b84fbc7e85f96cbe","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"72839a6ba27c45429e27d302a63a782f","deepnote_cell_type":"markdown"},"source":"## Fonction pour évaluer les performance d'un modèle","block_group":"72839a6ba27c45429e27d302a63a782f"},{"cell_type":"code","metadata":{"cell_id":"9d9b18f5fef3472c9a2a3439e6fa43b6","source_hash":"e393ae18","execution_start":1674764251787,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def validate(model, data, criterion):\n    \"\"\"\n    Cette fonction permet de calculer la précision pour l'ensemble\n    des classes prédites d'un modèle déja entrainé:\n        -model : modèle pré-entrainé\n        -data : set de donnée validation ou entrainement\n        -criterion : la fonction de coût utilisé lors de l'apprentissage\n    \"\"\"\n    model.eval()\n    \n    #Evaluation des vrais positifs et vrais négatifs\n    nb_correct_predictions = [0] * 2 #2 classes\n    nb_total_predictions = [0] * 2 #2 classes\n    \n    y_true = []\n    y_pred = []\n    \n    with torch.no_grad():\n        for inputs, labels in data:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            y_true += labels.tolist()\n            y_pred += predicted.tolist()\n            \n            balanced_acc = balanced_accuracy_score(y_true, y_pred)\n            \n            for i in range(len(labels)):\n                if labels[i] == predicted[i]:\n                    nb_correct_predictions[labels[i]] += 1\n                nb_total_predictions[labels[i]] += 1\n                \n    good_pred = [nb_correct_predictions[i] / nb_total_predictions[i] for i in range(len(data.dataset.classes))]\n    \n    return good_pred, balanced_acc","block_group":"9d9b18f5fef3472c9a2a3439e6fa43b6","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"cf1578f58b8f434fb5d2458074c7e706","deepnote_cell_type":"markdown"},"source":"## Entrainement et évaluation des perfomances du modèle ","block_group":"cf1578f58b8f434fb5d2458074c7e706"},{"cell_type":"code","metadata":{"cell_id":"21f40ead69834d74847c1a27ffd287c2","source_hash":"31b7376d","execution_start":1674764254357,"execution_millis":12,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"def perf_evaluation(model, data_train, data_val, num_epochs,\n                    early_stopping_threshold,\n                    criterion, optimizer, scheduler):\n    \n    \"\"\"\n    Cette fonction permet d'entrainer un modèle.\n    La fonction renvoi le meilleurs modèle\n    avec les statistiques de perofrmance réseauen fonction de l'epoch\n    \n        -model : modèle a entrainer\n        -data_train : set d'apprentissage\n        -data_val : set de validation\n        \n        -num_epochs : le nombre d'epoques\n        -early_stopping_threshold : le nombre d'époque minimum\n            ou l'on n'observe aucune amèliariation des performances\n        -criterion : choix de la fonction de coût\n        -optimizer : choix de l'optimiseur\n        scheduler : \n    \"\"\"\n\n    counter = 0\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n    \n    bal_acc_train = []\n    bal_acc_val = []\n    \n    true_neg_train = []\n    true_pos_train = []\n    \n    true_neg_val = []\n    true_pos_val = []\n    \n    time_list = []\n    epoch_list = []\n    \n    for epoch in range(num_epochs):\n        \n        #Entrainement du modèle et évaluation du temps\n        #d'entrainement\n        start = time.time()\n        train(model, data_train, optimizer, criterion)\n        end = time.time()\n        \n        #Performances sur le set d'entrainement\n        perf_train = validate(model, data_train, criterion)\n        print(\"Train set. True negative : \", perf_train[0][0],\n                \"true positive\", perf_train[0][1],\n                \"balanced accuracy\", perf_train[1])\n        \n        #Performances sur le set de validation\n        perf_val = validate(model, data_val, criterion)\n        print(\"validation set. True negative : \", perf_val[0][0],\n                \"true positive\", perf_val[0][1],\n                \"balanced accuracy\", perf_val[1])\n        \n        bal_acc_train.append(perf_train[1])\n        bal_acc_val.append(perf_val[1])\n        \n        true_neg_train.append(perf_train[0][0])\n        true_pos_train.append(perf_train[0][1])\n        \n        true_neg_val.append(perf_val[0][0])\n        true_pos_val.append(perf_val[0][1])\n        \n        time_list.append(round((end-start) * 10**3))\n        epoch_list.append(epoch)\n        \n        \n        if perf_val[1] > best_acc:\n            best_acc = perf_val[1]\n            best_model_wts = model.state_dict()\n            counter = 0\n        else:\n            counter += 1\n\n        if counter >= early_stopping_threshold:\n            print(\"Early stopping at epoch: \", epoch+1)\n            break\n    \n    perf = pd.DataFrame({'balanced_acc_train' : bal_acc_train,\n                         'balanced_acc_val' : bal_acc_val,\n                         'true_negative_train' : true_neg_train,\n                         'true_positive_train' : true_pos_train,\n                         'true_negative_val' : true_neg_val,\n                         'true_positive_val' : true_pos_val,\n                         'epochs' : epoch_list,\n                         'time_ms': time_list})\n    \n    return best_model_wts, perf","block_group":"21f40ead69834d74847c1a27ffd287c2","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"ce090b4ef7834f11b830ed6b4c58a47d","deepnote_cell_type":"markdown"},"source":"# Liste des modèles\n\nPlusieurs architectures de réseaux sont possibles pour avoir plusieurs canaux :\n\n- modèle classique : pas de modifications. Afin d'utiliser ces derniers pour faire de la classification sur n versions d'une image, il faut alors les concaténer, ce qui est relativement simple.\n\n- modèle à n canaux d'entrée : on modifie la première couche de convolution de sorte à cette dernière ait autant de canaux d'entrée qu'il y a de version d'une même image. Mais il faudra alors créer une nouvelle classe et de nouvelles fonctions avec les attributs du data loader afin d'entraîner et d'utiliser ce neurone.\n\n- modèle à n réseaux réunis en un seul neurone de sortie : cette architecture vise à utiliser autant de réseaux qu'il y a de version d'une même image et lier l'ensemble des réseaux à un seul neurone de sortie. Attention cette architecture présente de nombreux désavantages (temps d'apprentissage et d'optimisation). D'autant plus que si nous entraîner les dernières couches du réseau le nombre de combinaisons possibles et le temps d'entraînement risque d'exploser. En plus de cela, il faudra également créer une nouvelle classe de data loader. Cela revient presque à avoir un système avec \"vote\"","block_group":"ce090b4ef7834f11b830ed6b4c58a47d"},{"cell_type":"code","metadata":{"cell_id":"67728ee6b2f14ede824561f04944bf19","source_hash":"182b7cdc","execution_start":1674764259415,"execution_millis":1161,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"mod = models.resnet18(pretrained=True)\nnum_ftrs = mod.fc.in_features\nmod.fc = nn.Linear(num_ftrs, 2)\n\nmod_green = models.resnet18(pretrained=True)\nnum_ftrs = mod_green.fc.in_features\nmod_green.fc = nn.Linear(num_ftrs, 2)\n\nmod_skelet = models.resnet18(pretrained=True)\nnum_ftrs = mod_skelet.fc.in_features\nmod_skelet.fc = nn.Linear(num_ftrs, 2)","block_group":"67728ee6b2f14ede824561f04944bf19","execution_count":8,"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/shared-libs/python3.9/py/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"d54e816c7bcb48c1ab2e1990596402bd","source_hash":"d3b01938","execution_start":1674646580183,"execution_millis":264,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"#mod_n_chanels = models.resnet18(pretrained=True)\n\n# Récupérer la première couche de convolution\n#conv1 = mod_n_chanels.conv1\n\n# paramètres de la nouvelle couche à n cannaux\n#in_channels = 3\n#out_channels = conv1.out_channels\n#kernel_size = conv1.kernel_size\n#stride = conv1.stride\n#padding = conv1.padding\n\n#Construction de la couche à n cannaux\n#conv_n_channels = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n#conv_n_channels.weight.data.copy_(conv1.weight.data)\n\n#mod_n_chanels.conv1 = conv_n_channels\n\n# Réinitialiser la dernière couche pour adapter au nombre de classes\n#num_ftrs = mod_n_chanels.fc.in_features\n#mod_n_chanels.fc = nn.Linear(num_ftrs, 2)","block_group":"d54e816c7bcb48c1ab2e1990596402bd","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"6aeadc18cc384670a544c724f4d6db4f","deepnote_cell_type":"markdown"},"source":"# Analyse des modèles","block_group":"6aeadc18cc384670a544c724f4d6db4f"},{"cell_type":"code","metadata":{"cell_id":"7e7922ea35bd4805bc9283e3455afa9e","source_hash":"86df0a60","execution_start":1674764262920,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"num_epochs = 200\nearly_stopping_threshold = 20\nlearning_rate = 0.1\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(mod.parameters())\nscheduler = StepLR(optimizer, step_size=10)","block_group":"7e7922ea35bd4805bc9283e3455afa9e","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"1c8087be582c4cc4a940460dcfefa8d8","source_hash":"3de455f5","execution_start":1674764264908,"execution_millis":7709,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"source":"best_model_wts, perf = perf_evaluation(mod, train_loader, test_loader, num_epochs,\n                                       early_stopping_threshold,\n                                       criterion, optimizer, scheduler)","block_group":"1c8087be582c4cc4a940460dcfefa8d8","execution_count":11,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model_wts, perf \u001b[38;5;241m=\u001b[39m \u001b[43mperf_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mearly_stopping_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn [7], line 43\u001b[0m, in \u001b[0;36mperf_evaluation\u001b[0;34m(model, data_train, data_val, num_epochs, early_stopping_threshold, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     39\u001b[0m     \n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m#Entrainement du modèle et évaluation du temps\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m#d'entrainement\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#Performances sur le set d'entrainement\u001b[39;00m\n","Cell \u001b[0;32mIn [5], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#réinitialisation du gradient\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torchvision/models/resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torchvision/models/resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"cell_id":"ca700e9bb7e4413b9c33216b2d0bf7be","source_hash":"707f441f","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"#Sauvegarde du modèle\ntorch.save(best_model_wts.state_dict(),'/work/Models_history/mod1.pth')","block_group":"ca700e9bb7e4413b9c33216b2d0bf7be","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"19e2457bbb6a431389a5a86b751bda5c","source_hash":"ce3b377c","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"perf","block_group":"19e2457bbb6a431389a5a86b751bda5c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"848aea46ab0b46758fce54af8a3ec56c","deepnote_cell_type":"markdown"},"source":"# Optimisation des paramètres","block_group":"848aea46ab0b46758fce54af8a3ec56c"},{"cell_type":"code","metadata":{"cell_id":"8ce0853ac7964f1cbc2150fc45ec81b4","source_hash":"7446d24f","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"param_grid = {'step_size': [1, 5, 7, 10, 20, 30, 50, 100],\n              'gamma': [0.001, 0.01, 0.1, 0.5, 1, 10]}","block_group":"8ce0853ac7964f1cbc2150fc45ec81b4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"05392a404c7a458a8c5230aed71a3894","source_hash":"c2d2333","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"model = models.resnet18()\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2)\n\nmodel.load_state_dict(best_model_wts)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters())","block_group":"05392a404c7a458a8c5230aed71a3894","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"5b8f011465f8456a806c4320b63adad3","source_hash":"fc31fd85","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"grid = GridSearchCV(model, param_grid={'step_size': step_size_range,\n                                       'gamma': gamma_range}, cv=5)","block_group":"5b8f011465f8456a806c4320b63adad3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"979805c4f29f4aa3af91cd4691b1f080","source_hash":"d58f641d","deepnote_to_be_reexecuted":true,"deepnote_cell_type":"code"},"source":"grid.fit(train_loader)","block_group":"979805c4f29f4aa3af91cd4691b1f080","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6f211ba4-8439-4b4f-a72d-48759d094385' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"36566aa5c9f0405d84a961bc5be0a0cf","deepnote_execution_queue":[]}}