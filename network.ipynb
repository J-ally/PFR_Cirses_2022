{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a42715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delpi\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\delpi\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48eee3",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9b637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.utils.data.DataLoader récupère lui même les classes des images\n",
    "#Il suffit juste que les données \n",
    "train = torchvision.datasets.ImageFolder(root='C:\\\\Users\\\\delpi\\\\Mon Drive\\\\COURS\\\\AgroParisTech\\\\3A IODAA\\\\Fil rouge\\\\CIRSE\\\\training', transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "test = torchvision.datasets.ImageFolder(root='C:\\\\Users\\\\delpi\\\\Mon Drive\\\\COURS\\\\AgroParisTech\\\\3A IODAA\\\\Fil rouge\\\\CIRSE\\\\test', transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c885e",
   "metadata": {},
   "source": [
    "# Création des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae97a1e",
   "metadata": {},
   "source": [
    "Pour le moment, nous avons enlever juste le dernier neurone.\n",
    "En fonction des résultats obtenus nous devrons probablement enlever quelques couches vers la fin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd9db9",
   "metadata": {},
   "source": [
    "## Fonction d'entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f1a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Cette fonction permet d'entrainer un réseau de neuronne :\n",
    "        -model : le réseau à entrainer\n",
    "        -train_loader : le set d'entrainement (issus de torch.utils.data.DataLoader)\n",
    "        -optimizer : choix de l'optimiseur\n",
    "        -criterion : choix de la fonction de coût\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        #réinitialisation du gradient\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8b29e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000025EA1B5CF70>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c418ea2",
   "metadata": {},
   "source": [
    "## Fonction pour valider le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57908674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, criterion):\n",
    "    \"\"\"\n",
    "    Cette fonction permet de calculer la précision d'un modèle déja entrainé:\n",
    "        -model : modèle pré-entrainé\n",
    "        -data : set de donnée validation ou entrainement\n",
    "        -criterion : la fonction de coût utilisé lors de l'apprentissage\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    #Evaluation de l'accuracy pour chaque classe étant donnée qu'on est dans un cas déséquilibré\n",
    "    nb_correct_predictions = [0] * len(data.dataset.classes)\n",
    "    nb_total_predictions = [0] * len(data.dataset.classes)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                if labels[i] == predicted[i]:\n",
    "                    nb_correct_predictions[labels[i]] += 1\n",
    "                nb_total_predictions[labels[i]] += 1\n",
    "                \n",
    "    accuracy = [nb_correct_predictions[i] / nb_total_predictions[i] for i in range(len(data.dataset.classes))]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78285677",
   "metadata": {},
   "source": [
    "## Liste des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1cb135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delpi\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\delpi\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 2 sorties pour absence et présence de cirses\n",
    "# Attention, il existe plusieurs versions de Resnet\n",
    "# Il faudra problablement en essayant d'autre\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Réinitialiser la dernière couche pour adapter au nombre de classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bcc3d",
   "metadata": {},
   "source": [
    "## Fonction pour tester les différents paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15014ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_evaluation(model,data_train, data_test, num_epochs, early_stopping_threshold, learning_rate, param_grid, criterion, optimizer, scheduler):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cette fonction permet pour un modèle donner de faire un grid_search afin de determiner le step_size et le gamma\n",
    "    à partir d'une liste. La fonction renvoi le modèle avec les meilleurs paramètres ainsi qu'une table de données\n",
    "    avec les statistiques de perofrmance du modèle.\n",
    "        -model : modèle a entrainer\n",
    "        -train : ze\n",
    "        -test : \n",
    "        -num_epochs : le nombre d'epoques\n",
    "        -early_stopping_threshold : le nombre d'époque minimum ou l'on n'observe aucune amèliariation des performances\n",
    "        -learning_rate : \n",
    "        -param_grid : liste des step_size et gamma a tester\n",
    "        -criterion : choix de la fonction de coût\n",
    "        -optimizer : choix de l'optimiseur\n",
    "        scheduler : \n",
    "    \"\"\"\n",
    "\n",
    "    counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    epoch_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    parameters_list = []\n",
    "    time_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        train(model, data_train, optimizer, criterion)\n",
    "        end = time.time()\n",
    "\n",
    "        train_acc = validate(model, data_train, criterion)\n",
    "        print(\"train acuracies :\",train_acc)\n",
    "        val_acc = validate(model, data_test, criterion)\n",
    "        print(\"validation acuracies :\",val_acc)\n",
    "        \n",
    "        epoch_list.append(epoch)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        parameters_list.append({'step_size': scheduler.step_size, 'gamma': scheduler.gamma})\n",
    "        time_list.append(round((end-start) * 10**3))\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        #Etant dans un cas désquilibré, nous voulons que tout les classes soient prédites avec précision\n",
    "        #==> le produit de l'accuracy de l'ensemble des classes doit donc être le plus élevée possible\n",
    "        #lors de l'évaluation du set de validation\n",
    "        if val_acc[1]*val_acc[0] > best_acc:\n",
    "            best_acc = val_acc[1]*val_acc[0]\n",
    "            best_model_wts = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= early_stopping_threshold:\n",
    "            print(\"Early stopping at epoch: \", epoch+1)\n",
    "            break\n",
    "    \n",
    "    return best_model_wts, epoch_list, train_acc_list, val_acc_list, parameters_list, time_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef795e",
   "metadata": {},
   "source": [
    "## Définition des paramètres à tester (gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8eba020",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3000\n",
    "early_stopping_threshold = 50\n",
    "learning_rate = 0.001\n",
    "param_grid = {'step_size': [5, 7, 10], 'gamma': [0.001, 0.01, 0.1, 0.5, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "627f18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "scheduler = StepLR(optimizer, step_size=10)\n",
    "grid_search = GridSearchCV(scheduler, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3f6dd",
   "metadata": {},
   "source": [
    "# Analyse des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acuracies : [1.0, 0.012578616352201259]\n",
      "validation acuracies : [1.0, 0.008547008547008548]\n",
      "train acuracies : [0.9796672828096118, 0.8867924528301887]\n",
      "validation acuracies : [0.9310689310689311, 0.717948717948718]\n",
      "train acuracies : [1.0, 0.49056603773584906]\n",
      "validation acuracies : [1.0, 0.2905982905982906]\n",
      "train acuracies : [0.9930683918669131, 0.9119496855345912]\n",
      "validation acuracies : [0.965034965034965, 0.6495726495726496]\n",
      "train acuracies : [0.8174676524953789, 0.9779874213836478]\n",
      "validation acuracies : [0.6573426573426573, 0.6324786324786325]\n",
      "train acuracies : [1.0, 0.9308176100628931]\n"
     ]
    }
   ],
   "source": [
    "best_model_wts, epoch_list, train_acc_list, val_acc_list, parameters_list, time_list = perf_evaluation(model,train_loader, test_loader, num_epochs, early_stopping_threshold, learning_rate, param_grid, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a845b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.DataFrame({'epoch' : epoch_list,\n",
    "                     'train_accuracy' : train_acc_list,\n",
    "                     'validation_accuracy' : val_acc_list,\n",
    "                     'parameters' : parameters_list,\n",
    "                     'time_ms': time_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea16646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
